<!DOCTYPE html>
<html lang="en">

<!-- <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About - Food Recognition System</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
    <script src="https://cdn.tailwindcss.com"></script>   
</head> -->

<style>
    body {
        font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
    }

    /* Center text for the about section */
    .text-center {
        text-align: center;
    }

    /* Margin bottom classes for spacing */
    .mb-1 {
        margin-bottom: 0.25rem;
        /* Adjust the value as needed */
    }

    .mb-2 {
        margin-bottom: 0.5rem;
        /* Adjust the value as needed */
    }

    .mb-4 {
        margin-bottom: 1rem;
        /* Adjust the value as needed */
    }

    /* Margin top classes for spacing */
    .mt-1 {
        margin-top: 0.25rem;
        /* Adjust the value as needed */
    }

    .mt-2 {
        margin-top: 0.5rem;
        /* Adjust the value as needed */
    }

    .mt-4 {
        margin-top: 1rem;
        /* Adjust the value as needed */
    }

    /* Text size classes */
    .text-xl {
        font-size: 1.25rem;
        /* Adjust the size as needed */
    }

    .text-2xl {
        font-size: 1.5rem;
        /* Adjust the size as needed */
    }

    .text-3xl {
        font-size: 1.875rem;
        /* Adjust the size as needed */
        line-height: 2.25rem;
    }

    .text-4xl {
        font-size: 2.25rem;
        /* Adjust the size as needed */
        line-height: 2.5rem;
    }

    /* Font weight classes */
    .font-normal {
        font-weight: 400;
    }

    .font-medium {
        font-weight: 500;
    }

    .font-bold {
        font-weight: 700;
    }

    /* Italic class */
    .italic {
        font-style: italic;
    }

    /* Link decoration class */
    .link-no-underline {
        text-decoration: none;
    }

    /* Hover state class for links */
    .link-hover:hover {
        text-decoration: underline;
    }

    /* Specific styles for the author's name to make it larger and bolder */
    .author-name {
        font-size: 1.25rem;
        /* Adjust the size as needed */
        /* font-weight: bold; */
        /* display: block; */
        color: rgb(3, 140, 244);
    }

    .author-name:hover,
    .author-name:focus {
        color: #ffa500;
        /* 鼠标悬停时的文字颜色 */
        text-decoration: none;
    }

    /* Institution and conference info, slightly smaller and lighter weight */
    .institution-info,
    .conference-info {
        font-size: 1.125rem;
        /* Adjust the size as needed */
        font-weight: normal;
        text-decoration: none;
        font-weight: bold;
    }

    .institution-info:hover,
    .institution-info:focus {
        color: #ffa500;
        /* 鼠标悬停时的文字颜色 */
        text-decoration: none;
    }

    .wz {
        text-align: center;
    }

    .ab {
        width: 750px;
        margin-left: auto;
        margin-right: auto;
    }
</style>
<body class="bg-gray-100 text-gray-800" id="app">
    <header style="background-color: #fea121; color: white;">
        <div class="container mx-auto flex justify-between items-center p-4">
          <div class="flex items-center">
            <img src="{{ url_for('static', filename='src/OIP.png') }}" width="50" height="50" alt="Logo" class="logo">
            <h1 class="text-2xl font-bold">Food Recognition System</h1>
          </div>
          <nav class="flex gap-4">
            <a href="/" class="ho hover:text-orange-200">Main</a>
            <a href="/about" class="ho hover:text-orange-200">About</a>
            <a href="/qa" class="ho hover:text-orange-200">Q&A</a>
          </nav>
        </div>
      </header>

    <main class="container mx-auto my-8 px-4">
        <section class="mb-8">
            <h2 class="text-3xl font-bold text-center mb-4">About Our System</h2>
            <div class="text-center mb-8">
                <div class="text-center mb-4">
                    <h1 class="text-4xl font-bold mb-2">Web-based Food Recognition System</h1>
                    <a href="https://ylexliao.github.io/" class="author-name link-no-underline link-hover">LIAO
                        Yijie</a>
                    <br>
                    <a href="https://www.hkbu.edu.hk/" class="institution-info link-no-underline link-hover">Hong Kong
                        Baptist University</a>
                    <!-- <p class="institution-info">Hong Kong Baptist University</p> -->
                    <p class="conference-info ">Final Year Project 2024</p>
                </div>

                <div class="flex justify-center items-center my-4">
                    <a href="https://drive.google.com/file/d/1YzGF54Nfw4Z-VQPMDo-UR4hm79nHGwg9/view?usp=sharing"
                        class="button paper">
                        <svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" aria-hidden="true"
                            role="img" fill="currentColor">
                            <path
                                d="M854.6 288.7c6 6 9.4 14.1 9.4 22.6V928c0 17.7-14.3 32-32 32H192c-17.7 0-32-14.3-32-32V96c0-17.7 14.3-32 32-32h424.7c8.5 0 16.7 3.4 22.7 9.4l215.2 215.3zM790.2 326L602 137.8V326h188.2zM633.217 637.256c-15.174-0.489-31.314 0.67-49.65 2.964-24.298-14.987-40.654-35.582-52.274-65.827 0.28-1.152 0.86-3.538 1.063-4.38 0.474-1.958 0.867-3.594 1.243-5.185 4.293-18.13 6.615-31.358 7.3-44.695 0.518-10.074-0.04-19.368-1.827-27.976-3.298-18.584-16.454-29.453-33.021-30.126-15.446-0.627-29.649 7.993-33.281 21.373-5.913 21.612-2.45 50.07 10.08 98.582-15.964 38.056-37.052 82.661-51.203 107.539-18.885 9.74-33.604 18.605-45.953 28.427-16.303 12.966-26.48 26.29-29.286 40.306-1.355 6.48 0.692 14.966 5.36 21.912 5.296 7.879 13.282 12.991 22.855 13.735 24.152 1.877 53.83-23.024 86.59-79.258 3.295-1.09 6.78-2.257 11.026-3.69 2.323-0.783 10.464-3.538 11.91-4.026 7.521-2.54 12.98-4.36 18.376-6.116 23.396-7.612 41.096-12.429 57.21-15.163 27.973 14.973 60.316 24.796 82.098 24.796 17.979 0 30.126-9.319 34.515-23.985 3.857-12.886 0.794-27.824-7.473-36.084-8.56-8.41-24.3-12.434-45.658-13.123z m-247.985 128.42v-0.36l0.126-0.338c1.275-3.421 3.157-7.008 5.6-10.758 4.284-6.576 10.173-13.5 17.472-20.865 3.92-3.955 8.002-7.8 12.79-12.12 1.073-0.969 7.91-7.059 9.189-8.25l11.176-10.407-8.12 12.934c-12.326 19.638-23.46 33.78-33.013 43.004-3.507 3.387-6.6 5.9-9.091 7.505-1.027 0.662-1.916 1.144-2.613 1.424-0.409 0.163-0.771 0.268-1.13 0.302a2.202 2.202 0 0 1-1.117-0.16 2.068 2.068 0 0 1-1.269-1.911z m125.934-218.269l-2.26 4.007-1.39-4.385c-3.114-9.829-5.387-24.641-6.016-37.997-0.716-15.197 0.49-24.323 5.286-24.323 6.74 0 9.831 10.808 10.076 27.053 0.216 14.28-2.03 29.142-5.696 35.645z m-5.81 58.464l1.534-4.05 2.088 3.795c11.69 21.245 26.858 38.967 43.538 51.315l3.595 2.662-4.38 0.904c-16.328 3.372-31.544 8.457-52.34 16.842 2.174-0.876-21.623 8.863-27.638 11.169l-5.252 2.013 2.802-4.877c12.35-21.496 23.758-47.326 36.052-79.773z m157.626 76.261c-7.864 3.104-24.777 0.329-54.569-12.387l-7.561-3.227 8.199-0.607c23.295-1.724 39.807-0.44 49.422 3.08 4.09 1.498 6.824 3.388 8.037 5.553 1.31 2.336 0.71 4.81-1.362 6.31-0.448 0.427-1.155 0.88-2.166 1.278z"
                                p-id="3836" />
                        </svg>
                        Paper
                    </a>
                    <a href="https://drive.google.com/file/d/1YzGF54Nfw4Z-VQPMDo-UR4hm79nHGwg9/view?usp=sharing"
                        class="button supp">
                        <svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" aria-hidden="true"
                            role="img" fill="currentColor">
                            <path
                                d="M854.6 288.7c6 6 9.4 14.1 9.4 22.6V928c0 17.7-14.3 32-32 32H192c-17.7 0-32-14.3-32-32V96c0-17.7 14.3-32 32-32h424.7c8.5 0 16.7 3.4 22.7 9.4l215.2 215.3zM790.2 326L602 137.8V326h188.2zM633.217 637.256c-15.174-0.489-31.314 0.67-49.65 2.964-24.298-14.987-40.654-35.582-52.274-65.827 0.28-1.152 0.86-3.538 1.063-4.38 0.474-1.958 0.867-3.594 1.243-5.185 4.293-18.13 6.615-31.358 7.3-44.695 0.518-10.074-0.04-19.368-1.827-27.976-3.298-18.584-16.454-29.453-33.021-30.126-15.446-0.627-29.649 7.993-33.281 21.373-5.913 21.612-2.45 50.07 10.08 98.582-15.964 38.056-37.052 82.661-51.203 107.539-18.885 9.74-33.604 18.605-45.953 28.427-16.303 12.966-26.48 26.29-29.286 40.306-1.355 6.48 0.692 14.966 5.36 21.912 5.296 7.879 13.282 12.991 22.855 13.735 24.152 1.877 53.83-23.024 86.59-79.258 3.295-1.09 6.78-2.257 11.026-3.69 2.323-0.783 10.464-3.538 11.91-4.026 7.521-2.54 12.98-4.36 18.376-6.116 23.396-7.612 41.096-12.429 57.21-15.163 27.973 14.973 60.316 24.796 82.098 24.796 17.979 0 30.126-9.319 34.515-23.985 3.857-12.886 0.794-27.824-7.473-36.084-8.56-8.41-24.3-12.434-45.658-13.123z m-247.985 128.42v-0.36l0.126-0.338c1.275-3.421 3.157-7.008 5.6-10.758 4.284-6.576 10.173-13.5 17.472-20.865 3.92-3.955 8.002-7.8 12.79-12.12 1.073-0.969 7.91-7.059 9.189-8.25l11.176-10.407-8.12 12.934c-12.326 19.638-23.46 33.78-33.013 43.004-3.507 3.387-6.6 5.9-9.091 7.505-1.027 0.662-1.916 1.144-2.613 1.424-0.409 0.163-0.771 0.268-1.13 0.302a2.202 2.202 0 0 1-1.117-0.16 2.068 2.068 0 0 1-1.269-1.911z m125.934-218.269l-2.26 4.007-1.39-4.385c-3.114-9.829-5.387-24.641-6.016-37.997-0.716-15.197 0.49-24.323 5.286-24.323 6.74 0 9.831 10.808 10.076 27.053 0.216 14.28-2.03 29.142-5.696 35.645z m-5.81 58.464l1.534-4.05 2.088 3.795c11.69 21.245 26.858 38.967 43.538 51.315l3.595 2.662-4.38 0.904c-16.328 3.372-31.544 8.457-52.34 16.842 2.174-0.876-21.623 8.863-27.638 11.169l-5.252 2.013 2.802-4.877c12.35-21.496 23.758-47.326 36.052-79.773z m157.626 76.261c-7.864 3.104-24.777 0.329-54.569-12.387l-7.561-3.227 8.199-0.607c23.295-1.724 39.807-0.44 49.422 3.08 4.09 1.498 6.824 3.388 8.037 5.553 1.31 2.336 0.71 4.81-1.362 6.31-0.448 0.427-1.155 0.88-2.166 1.278z"
                                p-id="3836" />
                        </svg>
                        More Visual Results</a>
                    <a href="https://github.com/ylexLiao/FYP-Food-Recognition-System" class="button code">
                        <svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" aria-hidden="true"
                            role="img" fill="currentColor">
                            <path
                                d="M512 85.333333C276.266667 85.333333 85.333333 276.266667 85.333333 512a426.410667 426.410667 0 0 0 291.754667 404.821333c21.333333 3.712 29.312-9.088 29.312-20.309333 0-10.112-0.554667-43.690667-0.554667-79.445333-107.178667 19.754667-134.912-26.112-143.445333-50.133334-4.821333-12.288-25.6-50.133333-43.733333-60.288-14.933333-7.978667-36.266667-27.733333-0.554667-28.245333 33.621333-0.554667 57.6 30.933333 65.621333 43.733333 38.4 64.512 99.754667 46.378667 124.245334 35.2 3.754667-27.733333 14.933333-46.378667 27.221333-57.045333-94.933333-10.666667-194.133333-47.488-194.133333-210.688 0-46.421333 16.512-84.778667 43.733333-114.688-4.266667-10.666667-19.2-54.4 4.266667-113.066667 0 0 35.712-11.178667 117.333333 43.776a395.946667 395.946667 0 0 1 106.666667-14.421333c36.266667 0 72.533333 4.778667 106.666666 14.378667 81.578667-55.466667 117.333333-43.690667 117.333334-43.690667 23.466667 58.666667 8.533333 102.4 4.266666 113.066667 27.178667 29.866667 43.733333 67.712 43.733334 114.645333 0 163.754667-99.712 200.021333-194.645334 210.688 15.445333 13.312 28.8 38.912 28.8 78.933333 0 57.045333-0.554667 102.912-0.554666 117.333334 0 11.178667 8.021333 24.490667 29.354666 20.224A427.349333 427.349333 0 0 0 938.666667 512c0-235.733333-190.933333-426.666667-426.666667-426.666667z" />
                        </svg>
                        Code + Pretrained Models
                    </a>

                    <a href="https://colab.research.google.com/drive/1ELkyG5LQyRcpTSpLCeXo7ZazyggNRDy0?usp=sharing"
                        class="button colab">
                        <svg class="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" aria-hidden="true"
                            role="img" fill="currentColor">
                            <path
                                d="M722.816 212.309333a300.074667 300.074667 0 0 0-210.346667 88.064 300.074667 300.074667 0 0 0-5.290666 418.432l102.186666-102.186666a155.562667 155.562667 0 0 1 219.733334-219.648l102.272-102.357334a300.074667 300.074667 0 0 0-208.554667-82.346666z m-421.162667 0.426667a300.074667 300.074667 0 0 0-208.554666 82.389333l102.016 102.016a155.434667 155.434667 0 0 1 214.314666 5.418667l73.984-126.848-4.266666-3.413333a300.074667 300.074667 0 0 0-177.493334-59.562667z m640.426667 92.672l-101.973333 101.973333a155.562667 155.562667 0 0 1-219.733334 219.733334l-102.656 102.698666a300.202667 300.202667 0 0 0 424.32-424.405333z m-859.648 0.426667a300.074667 300.074667 0 0 0-0.085333 413.056l102.272-102.272a155.434667 155.434667 0 0 1-0.170667-208.725334z m326.997333 316.714666a155.093333 155.093333 0 0 1-214.058666 4.821334L93.098667 729.6a299.904 299.904 0 0 0 384.298666 23.296l5.845334-4.778667z"
                                p-id="4868" />
                        </svg>
                        Colab Demo</a>
                </div>

                <!-- <h1 class="section-name">&#128293;  &#128293;</h1> -->
            </div>
        </section>

        <section class="mb-8">
            <h3 class="text-2xl font-bold mb-3">Technology Stack</h3>
            <p class="text-gray-600" style="text-align:justify">
                Our system is built on a robust stack of modern technologies designed for performance and scalability.
                We leverage the back-end flexibility of <strong>Flask</strong>, a lightweight and efficient web
                framework. The front end is powered by <strong>Vue.js</strong>, enabling dynamic user interfaces and
                seamless interaction. Core to our food recognition capabilities is a bespoke <strong>machine learning
                    model</strong>, trained on a comprehensive dataset to ensure accurate identification of various
                cuisines.
            </p>
        </section>

        <section class="mb-8">
            <h3 class="wz text-2xl font-bold mb-3">Recognize Result</h3>
            <div class="images2-container">
                <img src="{{ url_for('static', filename='src/t9.png') }}" alt="test image" class="test-image">
                <img src="{{ url_for('static', filename='src/t9_2.png') }}" alt="test image" class="test-image">
            </div>
            <br>
            <p class="text-gray-600" style="text-align:justify">
                Our testing process used food images outside the training dataset to process through DPANet and got the
                prediction results, which can be seen in the above. These images, together with their predicted labels,
                compose a result that illustrates the good discriminative power of the model for the prediction of
                various food categories. Notably, misclassified examples (<strong>highlighted in red</strong>) provide
                insight into areas of potential improvement, with misidentification visualized to facilitate observation
                of model improvement.
            </p>
        </section>

        <section class="mb-8">
            <h3 class="wz text-2xl font-bold mb-3">Abstract</h3>
            <p class="ab text-gray-600" style="text-align:justify">
                In the emerging field of computer vision, food recognition presents unique challenges due to the high
                degree of variability within categories and the need for fine-grained feature detection. This paper
                introduces a novel Deep learning model, called the <strong>Deep Progressive Attention Network
                    (DPANet)</strong>, designed to improve the accuracy of food recognition in complex visual tasks. It
                utilizes multi-scale feature learning and attention mechanisms to improve the accuracy of food
                classification tasks. In the current research of food recognition, the extraction of fine-grained
                features and the comprehensive utilization of global information are the key to improve the recognition
                performance. Based on the <strong>ResNet50 backbone</strong> network, the model introduces a dual-path
                system for processing global and local image features and is enhanced by progressive training
                strategies. DPANet innovatively solves this problem by integrating global feature learning, progressive
                local feature learning, and regional feature enhancement. The model structure consists of several key
                components: a multi-head attention module, a deep separable convolution, and a progressive feature
                learning module designed to capture key features in food images from different scales. I also introduce
                a hybrid loss function that combines cross-entropy loss and KL divergence loss to optimize the
                complementarity between global and local features. Experiments on the standard Food recognition dataset
                <strong>Food-101</strong> show that DPANet outperforms current traditional models in accuracy,
                demonstrating its effectiveness in fine-grained food recognition tasks. Moreover, the reproducibility of
                the results, the obstacles encountered including dataset limitations and computational constraints - are
                discussed, and future enhancements to the model architecture and training process are proposed.
            </p>
        </section>


        <section class="mb-8">
            <h3 class="wz text-2xl font-bold mb-3">Method</h3>
            <div class="images-container">
                <img src="{{ url_for('static', filename='src/Deep Progressive Attention Network Architecture - Horizontal and Detailed.png') }}"
                    alt="Model image" class="method-image">
                <img src="{{ url_for('static', filename='src/Single Food Recognition Model Training Workflow.png') }}"
                    alt="Training image" class="method-image">
            </div>
            <p class="text-gray-600" style="text-align:justify">
                Based on the inspiration from <strong>PRENet</strong>, the Deep Progressive Attention Network (DPANet)
                whose detailed structure can be seen in the above proposed in this paper aims to improve the performance
                of deep learning models in complex visual tasks by integrating different levels of feature learning and
                regional feature augmentation. Such a fusion of multi-scale feature learning and refined regional
                feature enhancement strategy can enable the model to achieve a deep understanding of the complex
                structure of the image. DPANet consists of three core components: <strong>Global Feature
                    Learning</strong> is responsible for extracting Feature expressions in the global view,
                <strong>Progressive Local Feature Learning</strong> is responsible for capturing detailed features from
                multiple scales, and progressive local feature learning is responsible for extracting detailed features
                from multiple scales. Moreover, gradual fusion and <strong>Region Feature Enhancement</strong> enhance
                the response of the model to key local information through the <strong>self-attention</strong>
                mechanism. The model will obtain the global class score via <strong>GlobalMaxPool2d</strong> and
                <strong>classifier A</strong> on the global feature learning branch, and the regional class score via
                <strong>AdaptiveAvgPool2d</strong> and <strong>classifier B</strong> on the regional feature learning
                branch. In addition, the <strong>KL divergence loss</strong> between the outputs of the two classifiers
                is calculated during the training phase. To ensure that the probability distributions produced by the
                two classifiers (the global feature classifier and the regional feature classifier) are as consistent as
                possible. The global class score and the regional class score are then combined and passed through a
                final classifier to produce the final class score. This design makes the network not only consider the
                global context information, but also strengthen the focus on key local areas, which is crucial for
                fine-grained classification tasks. Such a design lies in the joint learning of global and local features
                and the reinforcement of key regions through the attention mechanism to improve the accuracy of the
                final classification. As detailed in the schematic, the DPANet architecture is divided into distinctive
                branches, each with a specialized function in the overarching goal of nuanced food image classification.
            </p>
        </section>

        <section class="mb-8">
            <h3 class="wz text-2xl font-bold mb-3">Dataset</h3>
            <div class="images2-container">
                <img src="{{ url_for('static', filename='src/food101DatasetV.png') }}" alt="Food101Dataset image"
                    class="method-image">
                <img src="{{ url_for('static', filename='src/imgdisplay1.png') }}" alt="imgdisplay1 image"
                    class="dataset-image">
                <img src="{{ url_for('static', filename='src/imgdisplay2.png') }}" alt="imgdisplay2 image"
                    class="dataset-image">
            </div>
            <br>
            <p class="text-gray-600" style="text-align:justify">
                The <strong>Food-101 dataset</strong> was selected for its balance between variety and manageability.
                Food-101, introduced by Bossard et al. (2014), encompasses a diverse array of <strong>101 food
                    categories</strong>, amounting to a total of <strong>101,000 images</strong> and the example
                annotations can be found in the above image. It offers a robust platform for the exploration and
                development of food recognition systems, with each category consisting of 750 training samples and 250
                test samples. This project utilized the Food-101 dataset not only for its comprehensive coverage of food
                categories, suitable for real-world applications, but also for its more uniform data distribution which
                benefits model training. Some example data illustrate the variety within the Food-101 dataset,
                highlighting the challenges and opportunities it presents for classification tasks.
            </p>
        </section>

        <section class="mb-8">
            <h3 class="wz text-2xl font-bold mb-3">Acknowledgements</h3>
            <p class="text-gray-600" style="text-align:justify">
                In the process of this project, I am fortunate to have received the careful guidance and support of many
                outstanding individuals. In particular, I would like to extend my deepest thanks to my supervisor,
                Professor Wan Renjie. Since the second semester of my junior year, Professor Wan has been guiding me. He
                has not only provided me with rich academic resources, but also given me great support and encouragement
                in my further learning. In addition, I would like to thank Professor Chen Jie for his professional
                advice and suggestions during the presentation of my project. His meticulous observation and insight
                enabled me to make breakthroughs at key points of research and had a positive impact on the progress of
                the project. </p>
        </section>

        <section class="mb-8">
            <h3 class="text-2xl font-bold mb-3">Contact Information</h3>
            <div class="contact-details">
                <p>If you have any questions or would like to discuss the project further, please don't hesitate to
                    reach out.</p>
                <p><strong>Liao Yijie</strong></p>
                <p>Email: <a href="mailto:20250576@life.hkbu.edu.hk"
                        class="text-blue-500 hover:underline" style="text-decoration: none;">20250576@life.hkbu.edu.hk</a></p>
            </div>
        </section>

    </main>

    <footer class="bg-gray-200 text-gray-800">
        <div class="container mx-auto p-4 text-center">
            <p>&copy; 2024 Food Recognition System. All rights reserved.</p>
        </div>
    </footer>

    <!-- <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
    <script src="{{ url_for('static', filename='js/app.js') }}"></script> -->

    <script src="{{ url_for('static', filename='js/vue.global.min.js') }}"></script>
    <!-- <script src="{{ url_for('static', filename='js/vue.global.js') }}"></script> -->
    <script src="{{ url_for('static', filename='js/app.js') }}"></script>
</body>

</html>